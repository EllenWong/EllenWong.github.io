

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/computer.png">
  <link rel="icon" href="/img/cutecat.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="本周学习汇报">
  <meta name="author" content="EllenWong">
  <meta name="keywords" content="">
  
  <title>Weekly-220605 - WYM&#39;s Blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"ellenwong.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>EllenWong</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                Links
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/images/1-weeklynote/wn.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Weekly-220605">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-06-05 16:58" pubdate>
        June 5, 2022 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      31
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Weekly-220605</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：June 5, 2022 pm
                
              </p>
            
            <div class="markdown-body">
              <h3 id="本周学习汇报"><a href="#本周学习汇报" class="headerlink" title="本周学习汇报"></a>本周学习汇报</h3><span id="more"></span>
<blockquote>
<div>
            <input type="checkbox" disabled checked="checked">自然辩证法考试
          </div>
<div>
            <input type="checkbox" disabled checked="checked">原型学习综述
          </div>
<div>
            <input type="checkbox" disabled checked="checked">Prototypical Networks for Few-shot Learning
          </div>
<div>
            <input type="checkbox" disabled checked="checked">Rethinking Semantic Segmentation: A Prototype View
          </div>
</blockquote>
<h2 id="1-自然辩证法考试"><a href="#1-自然辩证法考试" class="headerlink" title="1. 自然辩证法考试"></a>1. 自然辩证法考试</h2><h3 id="1-1-部分资料整理"><a href="#1-1-部分资料整理" class="headerlink" title="1.1 部分资料整理"></a>1.1 部分资料整理</h3><p><img src="/images/1-weeklynote/220605/1-1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="1-2-考试题目"><a href="#1-2-考试题目" class="headerlink" title="1.2 考试题目"></a>1.2 考试题目</h3><p><img src="/images/1-weeklynote/220605/1-2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h2 id="2-关于原型学习"><a href="#2-关于原型学习" class="headerlink" title="2. 关于原型学习"></a>2. 关于原型学习</h2><p>张幸幸, 朱振峰, 赵亚威, 等. 机器学习中原型学习研究进展[J]. 软件学报, 2021: 0-0.</p>
<h3 id="2-1-原型学习目的"><a href="#2-1-原型学习目的" class="headerlink" title="2.1 原型学习目的"></a>2.1 原型学习目的</h3><ul>
<li>为<strong>消除数据冗余、发现数据结构、提高数据质量</strong>,原型学习是一种行之有效的方式.通过寻找一个原型集来表示目标集,以从样本空间进行数据约简,在增强数据可用性的同时,提升机器学习算法的执行效率.</li>
<li><strong>数据约简的两种方式</strong><ul>
<li>针对特征空间：特征降维、特征选择</li>
<li>针对样本空间：原型生成、原型选择</li>
</ul>
</li>
</ul>
<h3 id="2-2-原型学习的应用"><a href="#2-2-原型学习的应用" class="headerlink" title="2.2 原型学习的应用"></a>2.2 原型学习的应用</h3><p><img src="/images/1-weeklynote/220605/2-1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li><strong>对机器学习而言：</strong> 主动学习、自步学习、生成对抗网络、支持向量机、模型压缩</li>
<li><strong>对实际应用而言：</strong> 计算机视觉、模式识别、图像和自然语言处理、生物医学、传感网络、信息推荐等领域的众多应用</li>
<li><strong>对数据处理而言：</strong> 数据的快速存储、压缩、生成、清洗、可视化和标注</li>
</ul>
<h3 id="2-3-原型学习的相关工作"><a href="#2-3-原型学习的相关工作" class="headerlink" title="2.3 原型学习的相关工作"></a>2.3 原型学习的相关工作</h3><p><img src="/images/1-weeklynote/220605/2-2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li><strong>主要研究方向：</strong> 无监督原型学习。</li>
</ul>
<h3 id="2-4-原型学习监督方式"><a href="#2-4-原型学习监督方式" class="headerlink" title="2.4 原型学习监督方式"></a>2.4 原型学习监督方式</h3><h4 id="2-4-1-无监督原型学习"><a href="#2-4-1-无监督原型学习" class="headerlink" title="2.4.1 无监督原型学习"></a>2.4.1 无监督原型学习</h4><ul>
<li><strong>优化：</strong> 一个特定的准则，如设施选址、最大边缘相关度、稀疏编码等。<ul>
<li><strong>稀疏编码准则：</strong> 假定目标数据位于一个或多个子空间中,这样便于将原型选择问题转换为稀疏字典选择问题,并用字典重构误差衡量原型集在目标集中的重要性.</li>
<li><strong>设施选址准则：</strong> 一般则是基于给定的成对相似性或相异性,选择编码损失(服务成本)最小的数据点作为原型.其中原型集编码目标集的损失与原型的重要性成反比关系</li>
</ul>
</li>
<li><strong>目标：</strong> 选取目标数据集中最具代表性的一个子集。</li>
</ul>
<h4 id="2-4-2-半监督原型学习"><a href="#2-4-2-半监督原型学习" class="headerlink" title="2.4.2 半监督原型学习"></a>2.4.2 半监督原型学习</h4><ul>
<li><strong>目标：</strong> 了解每个原型的特定类别。</li>
<li><strong>方式：</strong> 引入一个源集,并将原型选择建模成设施选址问题,但是利用它从目标集中而不是源集中找出代表性样本。<br><img src="/images/1-weeklynote/220605/2-3.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="2-4-3-全监督原型学习"><a href="#2-4-3-全监督原型学习" class="headerlink" title="2.4.3 全监督原型学习"></a>2.4.3 全监督原型学习</h4><ul>
<li><strong>CPL：</strong> 通过最大化类内聚集度和类间散度,设计一个基于距离度量的原型损失函数,从而学习目标集中每一类别的数据原型.进而,将测试数据与所有原型做匹配,可以对测试集做出判决,最终实现高精度和强鲁棒的模式分类。</li>
</ul>
<p><img src="/images/1-weeklynote/220605/2-4.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="2-5-原型学习相关方法"><a href="#2-5-原型学习相关方法" class="headerlink" title="2.5 原型学习相关方法"></a>2.5 原型学习相关方法</h3><h4 id="2-5-1-基于相似度的原型学习"><a href="#2-5-1-基于相似度的原型学习" class="headerlink" title="2.5.1 基于相似度的原型学习"></a>2.5.1 基于相似度的原型学习</h4><ul>
<li><strong>方法：</strong> 最小化目标集和原型集之间的全局差异。</li>
<li><strong>K-Medoids</strong><script type="math/tex; mode=display">\min _{\mu_{j} \in Y, r_{i j}} \sum_{i=1}^{n} \sum_{j=1}^{k} r_{i j} D\left(y_{i}, \mu_{j}\right)</script>其中D代表一种距离测量方式，如欧氏距离。</li>
</ul>
<h4 id="2-5-2-基于行列式点过程的原型选择"><a href="#2-5-2-基于行列式点过程的原型选择" class="headerlink" title="2.5.2 基于行列式点过程的原型选择"></a>2.5.2 基于行列式点过程的原型选择</h4><ul>
<li><strong>目标集上的点模式的概率测度：</strong><script type="math/tex; mode=display">\begin{array}{c}
P(\Omega ; L)=\frac{\operatorname{det}\left(L_{\Omega}\right)}{\operatorname{det}(L+I)} \\
\sum_{\Omega \subseteq Y} \operatorname{det}\left(L_{\Omega}\right)=\operatorname{det}(L+I)
\end{array}</script></li>
<li>可以很好地解决抽样中的互斥性的问题，有利于形成原型集的多样性。</li>
</ul>
<h4 id="2-5-3-基于数据重构的原型学习"><a href="#2-5-3-基于数据重构的原型学习" class="headerlink" title="2.5.3 基于数据重构的原型学习"></a>2.5.3 基于数据重构的原型学习</h4><ul>
<li><strong>方法：</strong> 通过最小化原型集重构目标集的残差,来保证原型的可解释性.<br><img src="/images/1-weeklynote/220605/2-5.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
<h4 id="2-5-4-基于低秩逼近的原型选择"><a href="#2-5-4-基于低秩逼近的原型选择" class="headerlink" title="2.5.4 基于低秩逼近的原型选择"></a>2.5.4 基于低秩逼近的原型选择</h4><ul>
<li>思想： 主要思想是通过矩阵分解,并利用随机或贪婪算法来寻找低秩矩阵列的子集,使得目标集矩阵的几行(列)能够近似整个低秩矩阵,而这几行(列)即目标集的原型集.</li>
<li><strong>CUR 分解的本质</strong><script type="math/tex; mode=display">\min _{C, U, R}\|Y-C U R\|_{F}^{2}+f(C, R)</script></li>
</ul>
<p>其中f (C,R)表示施加在矩阵 C 和 R 上的约束,且矩阵 C 由目标集 Y 中的几列组成,而矩阵 R 由目标集 Y 中的几行组成.</p>
<h3 id="2-6-原型学习的未来方向"><a href="#2-6-原型学习的未来方向" class="headerlink" title="2.6 原型学习的未来方向"></a>2.6 原型学习的未来方向</h3><ul>
<li><strong>知识迁移驱动的原型生成：</strong> 根据其他有标注的样本提升原型学习可利用的信息量。</li>
<li><strong>有缺陷数据的原型生成：</strong> 给定的目标集数据,通常在底层特征空间和高层语义空间容易出现缺陷。</li>
<li><strong>原型分布式学习：</strong> 通过最大化利用分步式计算的效能,不仅保护各个工作站的数据信息,同时还可以有效解决传统原型学习算法的准确率与效率无法同时满足的问题。</li>
<li><strong>面向深度学习的原型学习：</strong> 原型学习方法通过识别信息量最大的训练实例来提高大规模数据集机器学习的数据效率。</li>
<li><strong>原型的质量评价体系：</strong> 原型学习问题迫切需要一个统一的数据驱动的评价标准,而非任务驱动的评价标准,以精准度量原型的质量,尤其是可解释性、代表性和多样性。</li>
</ul>
<h2 id="3-元学习-初步了解"><a href="#3-元学习-初步了解" class="headerlink" title="3. 元学习(初步了解)"></a>3. 元学习(初步了解)</h2><h3 id="3-1-题目-元学习研究综述"><a href="#3-1-题目-元学习研究综述" class="headerlink" title="3.1 题目: 元学习研究综述"></a>3.1 题目: 元学习研究综述</h3><p><a target="_blank" rel="noopener" href="http://cjc.ict.ac.cn/online/bfpub/lcf-20201214103607.pdf">论文链接</a></p>
<h3 id="3-2-内容"><a href="#3-2-内容" class="headerlink" title="3.2 内容"></a>3.2 内容</h3><ul>
<li><strong>提出目的：</strong> 针对传统神经网络模型泛化性能不足、对新种类任务适应性较差的特点.<strong>元学习的目的</strong>就是为了设计一种机器学习模型，这种模型有类似上面提到的人的学习特性，即使用少量样本数据，快速学习新的概念或技能.</li>
<li><strong>实例：</strong> 小样本学习.</li>
<li><strong>主要表现：</strong> 提高泛化性能、获取好的初始参数、通过少量计算和新训练数据即可在模型上实现和海量训练数据一样的识别准确度.</li>
<li><strong>元学习的三个要求</strong><ul>
<li>包含一个学习子系统；</li>
<li>利用以前学习中提取的元知识来获得经验，这些元知识来自单个数据集或不同领域；</li>
<li>动态选择学习偏差.<br><img src="/images/1-weeklynote/220605/3-1.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
</li>
</ul>
<h2 id="4-小样本学习的原型网络"><a href="#4-小样本学习的原型网络" class="headerlink" title="4. 小样本学习的原型网络"></a>4. 小样本学习的原型网络</h2><h4 id="Prototypical-Networks-for-Few-shot-Learning"><a href="#Prototypical-Networks-for-Few-shot-Learning" class="headerlink" title="Prototypical Networks for Few-shot Learning"></a>Prototypical Networks for Few-shot Learning</h4><p><img src="/images/1-weeklynote/220605/4-1.png" srcset="/img/loading.gif" lazyload alt=""><br><code>/2-Learn Method/2-Meta Learning/2-Prototypical Networks/2017-Prototypical Networks for Few-shot Learning(NIPS).pdf</code></p>
<h3 id="4-1-Introduction"><a href="#4-1-Introduction" class="headerlink" title="4.1 Introduction"></a>4.1 Introduction</h3><ul>
<li><strong>Problem:</strong> Few-shot classification,a classifier must generalize to new classes not seen in the training set.</li>
<li><strong>Method:</strong>  Learn a metric space,computing distances to prototype representations of each class.</li>
<li><strong>Advantages:</strong> they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results.</li>
<li><strong>Contributions</strong><ul>
<li>Formulate Prototypical Networks for both the <code>few-shot</code> and <code>zero-shot</code> settings.</li>
<li>Draw connections to <code>Matching Networks</code> in the one-shot setting, and analyze the underlying <code>distance function</code> used in the model.</li>
<li>Relate Prototypical Networks to <code>clustering</code> in order to justify the use of class means as prototypes when distances are computed with a <code>Bregman divergence</code>, such as <code>squared Euclidean distance</code>.</li>
</ul>
</li>
</ul>
<h3 id="4-2-Related-Work"><a href="#4-2-Related-Work" class="headerlink" title="4.2 Related Work"></a>4.2 Related Work</h3><ul>
<li><p><strong>Matching Networks:</strong> Uses an <strong>attention mechanism</strong> over a learned embedding of the labeled set of examples (the support set) to predict classes for the unlabeled points (the query set).Matching Networks can be interpreted as a <strong>weighted nearest-neighbor </strong>classifier applied within an embedding space.</p>
</li>
<li><p><strong>Meta-Learning:</strong> Training an LSTM to produce the updates to a classifier, given an episode, such that it will generalize well to<br>a test-set.</p>
</li>
</ul>
<h3 id="4-3-Methodology"><a href="#4-3-Methodology" class="headerlink" title="4.3 Methodology"></a>4.3 Methodology</h3><h4 id="4-3-1-Prototypical-Networks-in-the-few-shot-and-zero-shot-scenarios"><a href="#4-3-1-Prototypical-Networks-in-the-few-shot-and-zero-shot-scenarios" class="headerlink" title="4.3.1 Prototypical Networks in the few-shot and zero-shot scenarios."></a>4.3.1 Prototypical Networks in the few-shot and zero-shot scenarios.</h4><p><img src="/images/1-weeklynote/220605/4-2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="4-3-2-Training-Algorithm"><a href="#4-3-2-Training-Algorithm" class="headerlink" title="4.3.2 Training Algorithm"></a>4.3.2 Training Algorithm</h4><p><img src="/images/1-weeklynote/220605/4-3.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="4-4-Experiments"><a href="#4-4-Experiments" class="headerlink" title="4.4 Experiments"></a>4.4 Experiments</h3><ul>
<li><strong>Quantitative Analysis：</strong><br><img src="/images/1-weeklynote/220605/4-4.png" srcset="/img/loading.gif" lazyload alt=""><ul>
<li>Omniglot Few-shot Classification</li>
<li>miniImageNet Few-shot Classification</li>
<li>CUB Zero-shot Classification</li>
</ul>
</li>
</ul>
<h3 id="4-5-Conclusion-and-Future-Work"><a href="#4-5-Conclusion-and-Future-Work" class="headerlink" title="4.5 Conclusion and Future Work"></a>4.5 Conclusion and Future Work</h3><ul>
<li><strong>Prototypical Networks:</strong> Few-shot learning based on the idea that we can represent each class by the mean of its examples in a representation space learned by a neural network.</li>
<li>Achieve <strong>state-of-the-art</strong> results on the CUB-200 dataset.</li>
</ul>
<h2 id="5-原型视图在语义分割中的应用"><a href="#5-原型视图在语义分割中的应用" class="headerlink" title="5. 原型视图在语义分割中的应用"></a>5. 原型视图在语义分割中的应用</h2><h4 id="Rethinking-Semantic-Segmentation-A-Prototype-View"><a href="#Rethinking-Semantic-Segmentation-A-Prototype-View" class="headerlink" title="Rethinking Semantic Segmentation: A Prototype View"></a>Rethinking Semantic Segmentation: A Prototype View</h4><p><img src="/images/1-weeklynote/220605/5-1.png" srcset="/img/loading.gif" lazyload alt=""><br><a target="_blank" rel="noopener" href="https://github.com/tfzhou/ProtoSeg">GitHub</a><br><code>/6-Segmentation/1-Network/2022-Rethinking Semantic Segmentation- A Prototype View(CVPR oral).pdf</code></p>
<h3 id="5-1-Introduction"><a href="#5-1-Introduction" class="headerlink" title="5.1 Introduction"></a>5.1 Introduction</h3><ul>
<li><strong>Parametric Prototype Learning</strong><ul>
<li><strong>parametric softmax:</strong> pixel-wise features for dense prediction.</li>
<li><strong>query vectors:</strong> utilize a set of learnable vectors to query the dense embeddings for mask prediction.</li>
</ul>
</li>
<li><strong>Non-Parametric Prototype Learning</strong>: This paper.</li>
</ul>
<h4 id="5-1-1-Questions"><a href="#5-1-1-Questions" class="headerlink" title="5.1.1 Questions"></a>5.1.1 Questions</h4><h5 id="A-What-are-the-relation-and-difference-between-them-parametric-softmax-query-vectors"><a href="#A-What-are-the-relation-and-difference-between-them-parametric-softmax-query-vectors" class="headerlink" title="A. What are the relation and difference between them(parametric softmax/query vectors )?"></a>A. What are the relation and difference between them(parametric softmax/query vectors )?</h5><ul>
<li>parametric models based on learnable prototypes. Consider a segmentation task with C semantic classes. Most existing efforts seek to <strong>directly learn C class-wise prototypes</strong> – <strong>softmax weights or query vectors</strong> – for parametric, pixel-wise classification.</li>
</ul>
<h5 id="B-If-the-learnable-query-vectors-indeed-implicitly-capture-some-intrinsic-properties-of-data-is-there-any-better-way-to-achieve-this"><a href="#B-If-the-learnable-query-vectors-indeed-implicitly-capture-some-intrinsic-properties-of-data-is-there-any-better-way-to-achieve-this" class="headerlink" title="B. If the learnable query vectors indeed implicitly capture some intrinsic properties of data, is there any better way to achieve this?"></a>B. If the learnable query vectors indeed implicitly capture some intrinsic properties of data, is there any better way to achieve this?</h5><ul>
<li>more fundamental—&gt;&gt;C&amp;D.</li>
</ul>
<h5 id="C-What-are-the-limitations-of-this-learnable-prototype-based-parametric-paradigm"><a href="#C-What-are-the-limitations-of-this-learnable-prototype-based-parametric-paradigm" class="headerlink" title="C. What are the limitations of this learnable prototype based parametric paradigm?"></a>C. What are the limitations of this learnable prototype based parametric paradigm?</h5><ul>
<li><strong>representative ability:</strong> insufficient to describe <strong>rich intra-class variance</strong>. The prototypes are simply learned in a fully parametric manner, without considering their representative ability;</li>
<li><strong>parameters need:</strong> generalizability especially in the <strong>large-vocabulary</strong> case;</li>
<li><strong>intra-class compactness:</strong> only the relative relations between intra-class and inter-class distances are optimized; the actual distances between pixels and prototypes, i.e., <strong>intra-class compactness</strong>, are ignored.</li>
</ul>
<h5 id="D-How-to-address-these-limitations"><a href="#D-How-to-address-these-limitations" class="headerlink" title="D. How to address these limitations?"></a>D. How to address these limitations?</h5><ul>
<li><strong>Contribution:</strong> develop a nonparametric segmentation framework, based on non-learnable prototypes.</li>
<li><strong>Advantages:</strong><ul>
<li>each class is abstracted by <strong>a set of prototypes</strong>, well capturing class-wise characteristics and intra-class variance;</li>
<li>due to the <strong>nonparametric nature</strong>, the generalizability is improved;</li>
<li>via <strong>prototype-anchored metric learning</strong>, the pixel embedding space is shaped as well-structured, benefiting segmentation prediction eventually.<br><img src="/images/1-weeklynote/220605/5-2.png" srcset="/img/loading.gif" lazyload alt=""></li>
</ul>
</li>
</ul>
<h3 id="5-2-Related-Work"><a href="#5-2-Related-Work" class="headerlink" title="5.2 Related Work"></a>5.2 Related Work</h3><ul>
<li><strong>Semantic Segmentation.</strong></li>
<li><strong>Prototype Learning:</strong>  Based on the nearest neighbors rule– <code>the earliest prototype learning method</code>.</li>
<li><strong>Metric Learning:</strong> The goal of metric learning is to learn a <code>distance metric/embedding</code> such that similar samples are pulled together and dissimilar samples are pushed away.</li>
</ul>
<h3 id="5-3-Methodology"><a href="#5-3-Methodology" class="headerlink" title="5.3 Methodology"></a>5.3 Methodology</h3><p><img src="/images/1-weeklynote/220605/5-3.png" srcset="/img/loading.gif" lazyload alt=""></p>
<ul>
<li>Non-Learnable Prototype based Pixel Classification</li>
<li>Within-Class Online Clustering</li>
<li>Pixel-Prototype Contrastive Learning</li>
<li>Pixel-Prototype Distance Optimization</li>
<li>Network Learning and Prototype Update</li>
</ul>
<h3 id="5-4-Experiments"><a href="#5-4-Experiments" class="headerlink" title="5.4 Experiments"></a>5.4 Experiments</h3><ul>
<li><p><strong>Quantitative Analysis：</strong><br><img src="/images/1-weeklynote/220605/5-4.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
<li><p><strong>Qualitative Analysis：</strong><br><img src="/images/1-weeklynote/220605/5-5.png" srcset="/img/loading.gif" lazyload alt=""></p>
</li>
</ul>
<h3 id="5-5-Conclusion-and-Future-Work"><a href="#5-5-Conclusion-and-Future-Work" class="headerlink" title="5.5 Conclusion and Future Work"></a>5.5 Conclusion and Future Work</h3><p><strong>Conclusion</strong></p>
<ul>
<li>explicit prototypical representation for class-level statistics modeling;</li>
<li>better generalization with nonparametric pixel-category prediction;</li>
<li>direct optimization of the feature embedding space.</li>
</ul>
<p><strong>Future Work</strong></p>
<ul>
<li>directly resemble pixel- or region- level observations.</li>
</ul>
<h2 id="6-下一步计划"><a href="#6-下一步计划" class="headerlink" title="6. 下一步计划"></a>6. 下一步计划</h2><ul>
<li>调研扩散模型的一些内容</li>
<li>了解元学习和迁移学习的主要思想</li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Meta-Learning/">Meta Learning</a>
                    
                      <a class="hover-with-bg" href="/tags/Prototypical-Networks/">Prototypical Networks</a>
                    
                      <a class="hover-with-bg" href="/tags/Semantic-segmentation/">Semantic segmentation</a>
                    
                  </div>
                
              </div>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/06/12/1-Weekly-220612/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Weekly-220612</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/05/29/1-Weekly-220529/">
                        <span class="hidden-mobile">Weekly-220529</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"66d9351bc44d3e35c662","clientSecret":"91eaf9f3eff9eb4d326e8093a434b488d8e160b6","repo":"EllenWong.github.io","owner":"EllenWong","admin":["EllenWong"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: '0bef282598423fed50a9bc3c02b2f21d'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
